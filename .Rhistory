data_all["QID"][data_all["QID"] == "Q141"] <- "Q41"
data_all["QID"][data_all["QID"] == "Q142"] <- "Q42"
data_all["QID"][data_all["QID"] == "Q143"] <- "Q88"
data_all["QID"][data_all["QID"] == "Q144"] <- "Q89"
data_all["QID"][data_all["QID"] == "Q145"] <- "Q90"
data_all["QID"][data_all["QID"] == "Q146"] <- "Q10"
data_all["QID"][data_all["QID"] == "Q147"] <- "Q11"
data_all["QID"][data_all["QID"] == "Q148"] <- "Q12"
data_all["QID"][data_all["QID"] == "Q149"] <- "Q58"
data_all["QID"][data_all["QID"] == "Q150"] <- "Q50"
data_all["QID"][data_all["QID"] == "Q151"] <- "Q60"
data_all["QID"][data_all["QID"] == "Q152"] <- "Q95"
data_all["QID"][data_all["QID"] == "Q153"] <- "Q96"
data_all["QID"][data_all["QID"] == "Q154"] <- "Q99"
data_all["QID"][data_all["QID"] == "Q155"] <- "Q1"
data_all["QID"][data_all["QID"] == "Q156"] <- "Q2"
data_all["QID"][data_all["QID"] == "Q157"] <- "Q3"
# note that each of these item numbers is a repeat
data_all["repeat"][data_all["old_QID"] == "Q140"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q141"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q142"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q143"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q144"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q145"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q146"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q147"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q148"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q149"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q150"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q151"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q152"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q153"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q154"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q155"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q156"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q157"] <- 1
# sort the remaining data by task type
data_pic <- data_all %>% filter(Task.Type == 'pic')
data_tvjt <- data_all %>% filter(Task.Type == 'tvjt')
# Code the answer separately for experimental items and control items
# for experimental items, answer ==  1 if implicature is computed, 0 otherwise
data_pic_exp  = data_pic %>%
filter(Condition=='experimental') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'L' | choice == '2' & Pragmatic_True == 'R', '1', '0'))
# for the literal nonimplicature control items, 0 if the choice is low on the scale and 1 otherwise
data_pic_nonimp_someall  = data_pic %>%
filter(Scale =='someall' & Trial.Type == 'literal nonimplicature') %>%
mutate(answer  = ifelse(choice == '1', '1', '0'))
data_pic_nonimp_others  = data_pic %>%
filter(Scale !='someall' & Trial.Type == 'literal nonimplicature') %>%
mutate(answer  = ifelse(choice == '1', '0', '1'))
# for the other control items, 1 if the answer is correct, 0 otherwise
data_pic_controls  = data_pic %>%
filter(Trial.Type == 'literal implicature'| Trial.Type == 'literal maximal') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'L' | choice == '2' & Pragmatic_True == 'R', '1', '0'))
# make answer column numeric
data_pic_exp = transform(data_pic_exp, answer = as.numeric(answer))
data_pic_nonimp_someall = transform(data_pic_nonimp_someall, answer = as.numeric(answer))
data_pic_nonimp_others = transform(data_pic_nonimp_others, answer = as.numeric(answer))
data_pic_controls = transform(data_pic_controls, answer = as.numeric(answer))
# Code the answer separately for experimental items and control items
# for experimental items, 1 if implicature is computed, 0 otherwise
data_tvjt_exp  = data_tvjt %>%
filter(Condition=='experimental') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'T' | choice == '2' & Pragmatic_True == 'F', '1', '0'))
# for pragmatic implicature items where "correct" choice is shown, 1 if "correct choice is accepted, 0 if it is rejected
data_tvjt_prag_control  = data_tvjt %>%
filter(Condition !='experimental' & Trial.Type == 'pragmatic implicature') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'T' | choice == '2' & Pragmatic_True == 'F', '1', '0'))
# for the literal nonimplicature control items, 20 if low is offered and rejected, 21 if low is offered and accepted, 10 is high is offered and rejected, 11 if high is offered and accepted
data_tvjt_nonimp_someall_high  = data_tvjt %>%
filter(Scale =='someall' & Trial.Type == 'literal nonimplicature' & nchar(Cards.Offered) == 2) %>%
mutate(answer  = ifelse(choice == '1', '11', '10'))
data_tvjt_nonimp_someall_low  = data_tvjt %>%
filter(Scale =='someall' & Trial.Type == 'literal nonimplicature' & nchar(Cards.Offered) == 4) %>%
mutate(answer  = ifelse(choice == '1', '21', '20'))
data_tvjt_nonimp_others_high  = data_tvjt %>%
filter(Scale !='someall' & Trial.Type == 'literal nonimplicature' & nchar(Cards.Offered) == 2) %>%
mutate(answer  = ifelse(choice == '1', '11', '10'))
data_tvjt_nonimp_others_low  = data_tvjt %>%
filter(Scale !='someall' & Trial.Type == 'literal nonimplicature' & nchar(Cards.Offered) == 1) %>%
mutate(answer  = ifelse(choice == '1', '21', '20'))
# for the other control items, 1 if the answer is correct, 0 otherwise
data_tvjt_controls  = data_tvjt %>%
filter(Trial.Type == 'literal implicature'| Trial.Type == 'literal maximal') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'T' | choice == '2' & Pragmatic_True == 'F', '1', '0'))
# make answer column numeric
data_tvjt_exp = transform(data_tvjt_exp, answer = as.numeric(answer))
data_tvjt_prag_control = transform(data_tvjt_prag_control, answer = as.numeric(answer))
data_tvjt_nonimp_someall_high = transform(data_tvjt_nonimp_someall_high, answer = as.numeric(answer))
data_tvjt_nonimp_someall_low = transform(data_tvjt_nonimp_someall_low, answer = as.numeric(answer))
data_tvjt_nonimp_others_high = transform(data_tvjt_nonimp_others_high, answer = as.numeric(answer))
data_tvjt_nonimp_others_low = transform(data_tvjt_nonimp_others_low, answer = as.numeric(answer))
data_tvjt_controls = transform(data_tvjt_controls, answer = as.numeric(answer))
# for the other control items, participants get excluded if their accuracy is lower than 90%
# create a new table that contains the mean accuracy rate for each participant
table_id_acc_2 <- data_tvjt_controls %>% group_by(ResponseId)%>% summarise(mean_accuracy_tvjt=mean(answer))
# this line shows how many trial item in the tvjt is the accuracy rate based upon
num_tvjt <- length(unique(data_tvjt_controls$QID))
print(paste0("the accuracy rate in tvjt is based on participants' answer to ", num_tvjt," questions"))
# recombine the response coded dataframes
data_tvjt = bind_rows(data_tvjt_exp, data_tvjt_prag_control, data_tvjt_nonimp_someall_high, data_tvjt_nonimp_someall_low, data_tvjt_nonimp_others_high, data_tvjt_nonimp_others_low, data_tvjt_controls)
# merge "table_id_acc" with "data_tvjt"
data_tvjt <- data_tvjt %>% left_join(table_id_acc_2)
#### Combine data the data from both tasks
data_cleaned = bind_rows(data_tvjt, data_pic)
View(data_cleaned)
# Create a table that contains each participants accuracy across tasks
table_id_acc_combined = data_cleaned %>% group_by(ResponseId) %>% summarise(pic_acc = mean_accuracy_pic,tvjt_acc = mean_accuracy_tvjt)
View(data_cleaned)
# create a new table that contains the mean accuracy rate for each participant on the control items
table_id_acc <- data_pic_controls%>% group_by(ResponseId) %>% summarise(mean_accuracy_pic=mean(answer))
# create a new table that contains the mean accuracy rate for each participant on the control items
table_id_acc <- data_pic_controls%>% group_by(ResponseId) %>% summarise(mean_accuracy_pic=mean(answer))
# this line shows how many trial item in the pst is the accuracy rate based upon
num_pst <- length(unique(data_pic_controls$QID))
print(paste0("the accuracy rate in pst is based on participants' answer to ", num_pst," questions"))
# recombine the response coded dataframes
data_pic = bind_rows(data_pic_exp, data_pic_nonimp_someall, data_pic_nonimp_others, data_pic_controls)
# merge "table_id_acc" with "data_pic"
data_pic <- data_pic %>% left_join(table_id_acc)
# Additionally, we want to create a by participant low/high bias column for the remaining participants
table_highlow_bias = data_pic %>%
filter(Trial.Type == 'literal nonimplicature') %>%
group_by(ResponseId) %>%
summarise(scale_bias = mean(answer))
#Add this to the DF as well
data_pic <- data_pic %>% left_join(table_highlow_bias)
# import raw Qualtrics data from the raw_data folder of this repo
df <- read.csv("/Users/caseyfelton/Downloads/Pragmetrics_December 7, 2022_17.39.csv")
df = df[37:46,]
# import key document specifying information about each trial
key <- read.csv("../raw_data/PragmetricsKey.csv")
# delete the incomplete experiment records
df <- df %>% filter(Finished == 1)
# delete experiment records that were previews for debugging purposes
df = df %>% filter(DistributionChannel != "preview")
df <- df %>% select(!RecipientLastName:LocationLongitude)
df <- df %>% select(!c("StartDate","EndDate","Status","IPAddress","Finished", "Instructions_1", "Instructions_2"))
# transform the data into long format
data_long <- df %>% pivot_longer(cols = starts_with('Q'), names_to = "QID", values_to = "choice")
# remove null choice lines
data_long <- data_long %>% subset(data_long$choice != "")
# join the key to the data
data_all <- data_long %>% left_join(key, by = "QID")
# add columns for old IDs and whether or not an item was a duplicate
# (If you get an error here it might be that you are using the wrong key)
data_all = data_all %>% mutate(old_QID = QID)
data_all = data_all %>% mutate('repeat' = 0)
# replace QIDs of duplicate experimental items with the original QID of the item
data_all["QID"][data_all["QID"] == "Q140"] <- "Q40"
data_all["QID"][data_all["QID"] == "Q141"] <- "Q41"
data_all["QID"][data_all["QID"] == "Q142"] <- "Q42"
data_all["QID"][data_all["QID"] == "Q143"] <- "Q88"
data_all["QID"][data_all["QID"] == "Q144"] <- "Q89"
data_all["QID"][data_all["QID"] == "Q145"] <- "Q90"
data_all["QID"][data_all["QID"] == "Q146"] <- "Q10"
data_all["QID"][data_all["QID"] == "Q147"] <- "Q11"
data_all["QID"][data_all["QID"] == "Q148"] <- "Q12"
data_all["QID"][data_all["QID"] == "Q149"] <- "Q58"
data_all["QID"][data_all["QID"] == "Q150"] <- "Q50"
data_all["QID"][data_all["QID"] == "Q151"] <- "Q60"
data_all["QID"][data_all["QID"] == "Q152"] <- "Q95"
data_all["QID"][data_all["QID"] == "Q153"] <- "Q96"
data_all["QID"][data_all["QID"] == "Q154"] <- "Q99"
data_all["QID"][data_all["QID"] == "Q155"] <- "Q1"
data_all["QID"][data_all["QID"] == "Q156"] <- "Q2"
data_all["QID"][data_all["QID"] == "Q157"] <- "Q3"
# note that each of these item numbers is a repeat
data_all["repeat"][data_all["old_QID"] == "Q140"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q141"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q142"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q143"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q144"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q145"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q146"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q147"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q148"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q149"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q150"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q151"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q152"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q153"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q154"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q155"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q156"] <- 1
data_all["repeat"][data_all["old_QID"] == "Q157"] <- 1
# sort the remaining data by task type
data_pic <- data_all %>% filter(Task.Type == 'pic')
data_tvjt <- data_all %>% filter(Task.Type == 'tvjt')
# Code the answer separately for experimental items and control items
# for experimental items, answer ==  1 if implicature is computed, 0 otherwise
data_pic_exp  = data_pic %>%
filter(Condition=='experimental') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'L' | choice == '2' & Pragmatic_True == 'R', '1', '0'))
# for the literal nonimplicature control items, 0 if the choice is low on the scale and 1 otherwise
data_pic_nonimp_someall  = data_pic %>%
filter(Scale =='someall' & Trial.Type == 'literal nonimplicature') %>%
mutate(answer  = ifelse(choice == '1', '1', '0'))
data_pic_nonimp_others  = data_pic %>%
filter(Scale !='someall' & Trial.Type == 'literal nonimplicature') %>%
mutate(answer  = ifelse(choice == '1', '0', '1'))
# for the other control items, 1 if the answer is correct, 0 otherwise
data_pic_controls  = data_pic %>%
filter(Trial.Type == 'literal implicature'| Trial.Type == 'literal maximal') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'L' | choice == '2' & Pragmatic_True == 'R', '1', '0'))
# make answer column numeric
data_pic_exp = transform(data_pic_exp, answer = as.numeric(answer))
data_pic_nonimp_someall = transform(data_pic_nonimp_someall, answer = as.numeric(answer))
data_pic_nonimp_others = transform(data_pic_nonimp_others, answer = as.numeric(answer))
data_pic_controls = transform(data_pic_controls, answer = as.numeric(answer))
# create a new table that contains the mean accuracy rate for each participant on the control items
table_id_acc <- data_pic_controls%>% group_by(ResponseId) %>% summarise(mean_accuracy_pic=mean(answer))
# this line shows how many trial item in the pst is the accuracy rate based upon
num_pst <- length(unique(data_pic_controls$QID))
print(paste0("the accuracy rate in pst is based on participants' answer to ", num_pst," questions"))
# recombine the response coded dataframes
data_pic = bind_rows(data_pic_exp, data_pic_nonimp_someall, data_pic_nonimp_others, data_pic_controls)
# merge "table_id_acc" with "data_pic"
data_pic <- data_pic %>% left_join(table_id_acc)
# Additionally, we want to create a by participant low/high bias column for the remaining participants
table_highlow_bias = data_pic %>%
filter(Trial.Type == 'literal nonimplicature') %>%
group_by(ResponseId) %>%
summarise(scale_bias = mean(answer))
#Add this to the DF as well
data_pic <- data_pic %>% left_join(table_highlow_bias)
# Code the answer separately for experimental items and control items
# for experimental items, 1 if implicature is computed, 0 otherwise
data_tvjt_exp  = data_tvjt %>%
filter(Condition=='experimental') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'T' | choice == '2' & Pragmatic_True == 'F', '1', '0'))
# for pragmatic implicature items where "correct" choice is shown, 1 if "correct choice is accepted, 0 if it is rejected
data_tvjt_prag_control  = data_tvjt %>%
filter(Condition !='experimental' & Trial.Type == 'pragmatic implicature') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'T' | choice == '2' & Pragmatic_True == 'F', '1', '0'))
# for the literal nonimplicature control items, 20 if low is offered and rejected, 21 if low is offered and accepted, 10 is high is offered and rejected, 11 if high is offered and accepted
data_tvjt_nonimp_someall_high  = data_tvjt %>%
filter(Scale =='someall' & Trial.Type == 'literal nonimplicature' & nchar(Cards.Offered) == 2) %>%
mutate(answer  = ifelse(choice == '1', '11', '10'))
data_tvjt_nonimp_someall_low  = data_tvjt %>%
filter(Scale =='someall' & Trial.Type == 'literal nonimplicature' & nchar(Cards.Offered) == 4) %>%
mutate(answer  = ifelse(choice == '1', '21', '20'))
data_tvjt_nonimp_others_high  = data_tvjt %>%
filter(Scale !='someall' & Trial.Type == 'literal nonimplicature' & nchar(Cards.Offered) == 2) %>%
mutate(answer  = ifelse(choice == '1', '11', '10'))
data_tvjt_nonimp_others_low  = data_tvjt %>%
filter(Scale !='someall' & Trial.Type == 'literal nonimplicature' & nchar(Cards.Offered) == 1) %>%
mutate(answer  = ifelse(choice == '1', '21', '20'))
# for the other control items, 1 if the answer is correct, 0 otherwise
data_tvjt_controls  = data_tvjt %>%
filter(Trial.Type == 'literal implicature'| Trial.Type == 'literal maximal') %>%
mutate(answer  = ifelse(choice == '1' & Pragmatic_True == 'T' | choice == '2' & Pragmatic_True == 'F', '1', '0'))
# make answer column numeric
data_tvjt_exp = transform(data_tvjt_exp, answer = as.numeric(answer))
data_tvjt_prag_control = transform(data_tvjt_prag_control, answer = as.numeric(answer))
data_tvjt_nonimp_someall_high = transform(data_tvjt_nonimp_someall_high, answer = as.numeric(answer))
data_tvjt_nonimp_someall_low = transform(data_tvjt_nonimp_someall_low, answer = as.numeric(answer))
data_tvjt_nonimp_others_high = transform(data_tvjt_nonimp_others_high, answer = as.numeric(answer))
data_tvjt_nonimp_others_low = transform(data_tvjt_nonimp_others_low, answer = as.numeric(answer))
data_tvjt_controls = transform(data_tvjt_controls, answer = as.numeric(answer))
# for the other control items, participants get excluded if their accuracy is lower than 90%
# create a new table that contains the mean accuracy rate for each participant
table_id_acc_2 <- data_tvjt_controls %>% group_by(ResponseId)%>% summarise(mean_accuracy_tvjt=mean(answer))
# this line shows how many trial item in the tvjt is the accuracy rate based upon
num_tvjt <- length(unique(data_tvjt_controls$QID))
print(paste0("the accuracy rate in tvjt is based on participants' answer to ", num_tvjt," questions"))
# recombine the response coded dataframes
data_tvjt = bind_rows(data_tvjt_exp, data_tvjt_prag_control, data_tvjt_nonimp_someall_high, data_tvjt_nonimp_someall_low, data_tvjt_nonimp_others_high, data_tvjt_nonimp_others_low, data_tvjt_controls)
# merge "table_id_acc" with "data_tvjt"
data_tvjt <- data_tvjt %>% left_join(table_id_acc_2)
#### Combine data the data from both tasks
data_cleaned = bind_rows(data_tvjt, data_pic)
View(data_cleaned)
table_id_acc_combined = data_cleaned %>% group_by(ResponseId) %>% summarise(pic_acc = mean_accuracy_pic,tvjt_acc = mean_accuracy_tvjt)
table_id_acc_combined = distinct(table_id_acc_combined)
# Creates function to collapse rows
collapse <- function(x) x[!is.na(x)][1]
#Collapses rows
table_id_acc_combined = table_id_acc_combined %>% group_by(ResponseId) %>% summarise(pic_acc = collapse(pic_acc), tvjt_acc = collapse(tvjt_acc))
View(table_id_acc_combined)
View(table_id_acc_combined)
# Merge the new table with the cleaned data
data_cleaned = data_cleaned %>% left_join(table_id_acc_combined)
# Filter all participants with less than 90% accuracy
data_cleaned = data_cleaned %>% filter((pic_acc >= .9) & (tvjt_acc >= .9))
608/76
table(data$QID)
table(data_all$QID)
table(data_long$QID)
View(data_cleaned)
View(data_cleaned)
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('ggplot2')
library('lme4')
# Reads in data files
data_1 = read.csv('../Disjunction_Junction/Data&Resources/Real_Data/dis_junct_preliminary-trials.csv')
data_2 = read.csv('../Disjunction_Junction/Data&Resources/Real_Data/dis_junc_full_collection-trials.csv')
# Combines the data from the two csvs
data = rbind(data_1, data_2)
# Factorizes and renames id column
data = data %>%
mutate(ID = as.factor(id))
# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)
# Reads in key file
key = read.csv('../Disjunction_Junction/Data&Resources/disjunction_junction_key.csv')
# Factorizes IS column
key$ID = as_factor(key$ID)
# Joins key and data
data = left_join(data, key, by = 'ID')
#Filter just the 100% control items
cntr_100 = data %>% filter(ID == 48 | ID == 49 | ID == 50)
#Filter just the 0% control items
cntr_0 = data %>% filter(ID == 51 | ID == 52 | ID == 53)
#Adds a column for accuracy
cntr_100$correct = cntr_100$chance >= 90
cntr_0$correct = cntr_0$chance <= 10
#Combines the items
accuracy_check = rbind(cntr_0, cntr_100)
#Creates a table with the aggregated mean accuracy for each participant
accuracy_table = accuracy_check %>% group_by(workerid) %>% summarise(mean_accuracy = mean(correct))
#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = 'workerid')
#Filter out participants who got less than 5/6 correct (Starting with 50, 8 are excluded, leaving 42)
data = data %>% filter(mean_accuracy > .8)
means = data %>%
group_by(ID) %>%
summarise(Mean_Chance = mean(chance),
Standard_Deviation = sd(chance),
Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means)
graph_data = left_join(means, key, by = 'ID') %>% mutate(ID = fct_reorder(ID, Mean_Chance))
g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = Claimed.Bias)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
geom_errorbar(width = .5,
aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
position = position_dodge(.9)) +
theme_bw() +
theme(axis.text.x = element_blank())
# Filter out items with no recorded bias claim
model_data = data %>% filter(Claimed.Bias == 'Exclusive Biased' | Claimed.Bias == 'Inclusive Biased')
# transform column into factor
model_data$Claimed.Bias = as_factor(model_data$Claimed.Bias)
model_2 = lmer(chance ~ Claimed.Bias + (1 | workerid), data = model_data)
summary(model_2)
knitr::opts_chunk$set(echo = TRUE)
library(lmerTest)
# Reads in data files
data_1 = read.csv('../Disjunction_Junction/Data&Resources/Real_Data/dis_junct_preliminary-trials.csv')
data_2 = read.csv('../Disjunction_Junction/Data&Resources/Real_Data/dis_junc_full_collection-trials.csv')
# Combines the data from the two csvs
data = rbind(data_1, data_2)
# Factorizes and renames id column
data = data %>%
mutate(ID = as.factor(id))
#Filter just the 100% control items
cntr_100 = data %>% filter(ID == 48 | ID == 49 | ID == 50)
library('tidyverse')
library('ggplot2')
library('lme4')
library(lmerTest)
#Filter just the 100% control items
cntr_100 = data %>% filter(ID == 48 | ID == 49 | ID == 50)
setwd("~/Desktop/Githubs/disjunction_junction_html")
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('ggplot2')
library('lme4')
library('lmerTest')
# Reads in data files
data_1 = read.csv('../Disjunction_Junction/Data&Resources/Real_Data/dis_junct_preliminary-trials.csv')
data_2 = read.csv('../Disjunction_Junction/Data&Resources/Real_Data/dis_junc_full_collection-trials.csv')
# Combines the data from the two csvs
data = rbind(data_1, data_2)
# Factorizes and renames id column
data = data %>%
mutate(ID = as.factor(id))
# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)
# Reads in key file
key = read.csv('../Disjunction_Junction/Data&Resources/disjunction_junction_key.csv')
# Factorizes IS column
key$ID = as_factor(key$ID)
# Joins key and data
data = left_join(data, key, by = 'ID')
#Filter just the 100% control items
cntr_100 = data %>% filter(ID == 48 | ID == 49 | ID == 50)
#Filter just the 0% control items
cntr_0 = data %>% filter(ID == 51 | ID == 52 | ID == 53)
#Adds a column for accuracy
cntr_100$correct = cntr_100$chance >= 90
cntr_0$correct = cntr_0$chance <= 10
#Combines the items
accuracy_check = rbind(cntr_0, cntr_100)
#Creates a table with the aggregated mean accuracy for each participant
accuracy_table = accuracy_check %>% group_by(workerid) %>% summarise(mean_accuracy = mean(correct))
#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = 'workerid')
#Filter out participants who got less than 5/6 correct (Starting with 50, 8 are excluded, leaving 42)
data = data %>% filter(mean_accuracy > .8)
# Fixed version of the old model (will actually run, rank deficient when ID is a fixed effect)
model_2 = lmer(chance ~ Claimed.Bias + (1 | workerid), data = model_data)
# Filter out items with no recorded bias claim
model_data = data %>% filter(Claimed.Bias == 'Exclusive Biased' | Claimed.Bias == 'Inclusive Biased')
# Fixed version of the old model (will actually run, rank deficient when ID is a fixed effect)
model_2 = lmer(chance ~ Claimed.Bias + (1 | workerid), data = model_data)
summary(model_2)
View(model_data)
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'control'] = 'Control'
graph_data = left_join(means, key, by = 'ID') %>% mutate(ID = fct_reorder(ID, Mean_Chance))
means = data %>%
group_by(ID) %>%
summarise(Mean_Chance = mean(chance),
Standard_Deviation = sd(chance),
Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means)
graph_data = left_join(means, key, by = 'ID') %>% mutate(ID = fct_reorder(ID, Mean_Chance))
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'control'] = 'Control'
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'Exclusive Biased'] = 'Hypothesized Exclusive'
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'Inclusive Biased'] = 'Hypothesized Inclusive'
g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = Claimed.Bias)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
geom_errorbar(width = .5,
aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
position = position_dodge(.9)) +
theme_bw() +
theme(axis.text.x = element_blank())
View(graph_data)
rename?
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'control'] = 'Control'
?rename
rename(graph_data, 'Hypothesized Reading' = 'Claimed.Bias')
View(graph_data)
rename(graph_data, 'Claimed.Bias' = 'Hypothesized Reading')
graph_data = rename(graph_data, 'Hypothesized Reading' = 'Claimed.Bias')
View(graph_data)
g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = Claimed.Bias)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
geom_errorbar(width = .5,
aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
position = position_dodge(.9)) +
theme_bw() +
theme(axis.text.x = element_blank())
g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = Hypothesized Bias)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = 'Hypothesized Reading')) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
geom_errorbar(width = .5,
aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
position = position_dodge(.9)) +
theme_bw() +
theme(axis.text.x = element_blank())
g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = Hypothesized Reading)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
g + geom_col(position = "dodge", aes(fill = Hypothesized.Reading)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
geom_errorbar(width = .5,
aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
position = position_dodge(.9)) +
theme_bw() +
theme(axis.text.x = element_blank())
graph_data = left_join(means, key, by = 'ID') %>% mutate(ID = fct_reorder(ID, Mean_Chance))
graph_data = rename(graph_data, 'Hypothesized Reading' = 'Claimed.Bias')
?rename
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'control'] = 'Control'
means = data %>%
group_by(ID) %>%
summarise(Mean_Chance = mean(chance),
Standard_Deviation = sd(chance),
Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means)
graph_data = left_join(means, key, by = 'ID') %>% mutate(ID = fct_reorder(ID, Mean_Chance))
graph_data = rename(graph_data, 'Hypothesized Reading' = 'Claimed.Bias')
?rename
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'control'] = 'Control'
graph_data = left_join(means, key, by = 'ID') %>% mutate(ID = fct_reorder(ID, Mean_Chance))
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'control'] = 'Control'
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'Exclusive Biased'] = 'Hypothesized Exclusive'
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'Inclusive Biased'] = 'Hypothesized Inclusive'
graph_data = rename(graph_data, 'Hypothesized Reading' = 'Claimed.Bias')
g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = 'Hypothesized Reading')) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
geom_errorbar(width = .5,
aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
position = position_dodge(.9)) +
theme_bw() +
theme(axis.text.x = element_blank())
means = data %>%
group_by(ID) %>%
summarise(Mean_Chance = mean(chance),
Standard_Deviation = sd(chance),
Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means)
graph_data = left_join(means, key, by = 'ID') %>% mutate(ID = fct_reorder(ID, Mean_Chance))
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'control'] = 'Control'
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'Exclusive Biased'] = 'Hypothesized Exclusive'
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'Inclusive Biased'] = 'Hypothesized Inclusive'
graph_data = rename(graph_data, 'Hypothesized_Reading' = 'Claimed.Bias')
g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = Hypothesized_Reading)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
geom_errorbar(width = .5,
aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
position = position_dodge(.9)) +
theme_bw() +
theme(axis.text.x = element_blank())
g + geom_col(position = "dodge", aes(fill = Hypothesized_Reading)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
geom_errorbar(width = .5,
aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
position = position_dodge(.9)) +
theme_bw() +
theme(axis.text.x = element_blank())
