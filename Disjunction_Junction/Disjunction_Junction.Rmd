---
title: "Disjunction Junction"
output: html_document
date: '2022-10-11'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load required libraries
```{r, include= FALSE}
library('tidyverse')
library('ggplot2')
library('lme4')
library('lmerTest')
```

Read in and join raw data with the key
```{r}
# Reads in data files
data_1 = read.csv('../Disjunction_Junction/Data&Resources/Real_Data/dis_junct_preliminary-trials.csv')
data_2 = read.csv('../Disjunction_Junction/Data&Resources/Real_Data/dis_junc_full_collection-trials.csv')

# Combines the data from the two csvs
data = rbind(data_1, data_2)

# Factorizes and renames id column
data = data %>% 
  mutate(ID = as.factor(id))

# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)

# Reads in key file
key = read.csv('../Disjunction_Junction/Data&Resources/disjunction_junction_key.csv')

# Factorizes IS column
key$ID = as_factor(key$ID)

# Joins key and data
data = left_join(data, key, by = 'ID')
```

# Data Cleaning
There are a total of 6 attention checking control items, each of which should result in either close to 0% or close to 100% chance ratings from participants who were paying attention. The following code block excludes participants who did not rate at least 5 out of the 6 control items as within 10% of either 0% or 100%, whichever was accurate. 
```{r}
#Filter just the 100% control items
cntr_100 = data %>% filter(ID == 48 | ID == 49 | ID == 50)
#Filter just the 0% control items
cntr_0 = data %>% filter(ID == 51 | ID == 52 | ID == 53)

#Adds a column for accuracy
cntr_100$correct = cntr_100$chance >= 90
cntr_0$correct = cntr_0$chance <= 10

#Combines the items
accuracy_check = rbind(cntr_0, cntr_100)

#Creates a table with the aggregated mean accuracy for each participant
accuracy_table = accuracy_check %>% group_by(workerid) %>% summarise(mean_accuracy = mean(correct))

#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = 'workerid')

#Filter out participants who got less than 5/6 correct (Starting with 50, 8 are excluded, leaving 42)
data = data %>% filter(mean_accuracy > .8)
```

# Overview of Analysis
In the first phase of this experiment, we have 2 main hypothesis to test. 1. Whether participants rate the likelihood that the two disjuncts co-occur as either more or less likely than the baseline of "the two events are equally likely to co-occur or to occur separately". 2. Whether the direction of the bias in ratings matches the literature's prediction of inclusive or exclusive bias for the overall disjunction. 

# Hypothesis 1
The following code aggregates group means, standard deviations, and standard errors for each item
```{r}
means = data %>% 
  group_by(ID) %>% 
  summarise(Mean_Chance = mean(chance),
            Standard_Deviation = sd(chance),
            Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means)
```

The code below generates a plot with columns for the means and +/_ 1 SE errorbars
```{r}
graph_data = left_join(means, key, by = 'ID') %>% mutate(ID = fct_reorder(ID, Mean_Chance))

graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'control'] = 'Control'
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'Exclusive Biased'] = 'Hypothesized Exclusive'
graph_data$Claimed.Bias[graph_data$Claimed.Bias == 'Inclusive Biased'] = 'Hypothesized Inclusive'

graph_data = rename(graph_data, 'Hypothesized_Reading' = 'Claimed.Bias')

g = ggplot(graph_data, aes(ID, Mean_Chance))
g + geom_col(position = "dodge", aes(fill = Hypothesized_Reading)) + labs(title = 'Means and Variation by Item', x = 'Items', y = 'Rated Likelihood of Cooccurence (0%-100%)')+
  geom_errorbar(width = .5,
                aes(ymin = Mean_Chance - Standard_Error*2, ymax = Mean_Chance + Standard_Error*2),
                position = position_dodge(.9)) +
               theme_bw() +
               theme(axis.text.x = element_blank())
```

### The next section uses a linear model to test the second hypothesis
```{r}
# Filter out items with no recorded bias claim
model_data = data %>% filter(Claimed.Bias == 'Exclusive Biased' | Claimed.Bias == 'Inclusive Biased')

# transform column into factor
model_data$Claimed.Bias = as_factor(model_data$Claimed.Bias)

# An exploratory basic lm()
model_0 = lm(chance ~ Claimed.Bias, data = model_data)
summary(model_0)

# Fixed version of the old model (will actually run, rank deficient when ID is a fixed effect)
model_2 = lmer(chance ~ Claimed.Bias + (1 | workerid), data = model_data)
summary(model_2)

```

