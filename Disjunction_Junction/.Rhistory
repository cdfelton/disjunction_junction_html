scale_y_continuous(breaks = c(1:8)) +
theme_classic()
## Note: I set alpha = .3 in the geom_point() to make the points only 30% opaque
## (i.e., 70% transparent). I did this because there are many overlapping data
## points (this is common when you have Likert scale variables), and so by
## making the points transparent you get a better sense of how many data points
## are at each X-Y pairing.
ggplot(data = lab.data,
aes(x = Pray_04, y = Bible_04)) +
geom_smooth(method = "lm") +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
scale_x_continuous(breaks = c(1:8)) +
scale_y_continuous(breaks = c(1:8)) +
geom_vline(xintercept = 5, linetype = "dashed") +
geom_hline(yintercept = (-0.5040 + 0.7747*(5)), linetype = "dashed") +
theme_classic()
# We can get a little more information out of the regression model with
# the summary() function:
lm(Bible_04 ~ Pray_04, data = lab.data) %>% summary()
summary(lm(scale(Bible_04) ~ scale(Pray_04), data = lab.data))
#For simple regressions, the beta-weight will always be the same as Pearson r.
corr.test(lab.data[,c("Bible_04","Pray_04")])$r
corr_matrix = alex_data %>% select(Pace.mph, Run.Minutes, Laps, Total.Days.Since.Start, Time.of.Day) %>% corr.test()
corr_matrix
ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm") +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
theme_classic()
ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm") +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Run Duration', x = 'Run Duration in Minutes', y = 'Running Pace in Miles Per Hour')+
theme_classic()
1 = ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm") +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Run Duration', x = 'Run Duration in Minutes', y = 'Running Pace in Miles Per Hour')+
theme_classic()
graph_1 = ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm") +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Run Duration', x = 'Run Duration in Minutes', y = 'Running Pace in Miles Per Hour')+
theme_classic()
View(graph_1)
graph_1 = ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'green"') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Run Duration', x = 'Run Duration in Minutes', y = 'Running Pace in Miles Per Hour')+
theme_classic()
graph_1
ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'green"') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Run Duration', x = 'Run Duration in Minutes', y = 'Running Pace in Miles Per Hour')+
theme_classic()
ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'green') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Run Duration', x = 'Run Duration in Minutes', y = 'Running Pace in Miles Per Hour')+
theme_classic()
ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'red') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Run Duration', x = 'Run Duration in Minutes', y = 'Running Pace in Miles Per Hour')+
theme_classic()
# Laps x Pace
ggplot(data = alex_data,
aes(x = Laps, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'red') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Laps Run', x = 'Total Laps Run', y = 'Running Pace in Miles Per Hour')+
theme_classic()
ggplot(data = alex_data,
aes(x = Total.Days.Since.Start, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'green') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Total Days Since Start', x = 'Total Days Since Start', y = 'Running Pace in Miles Per Hour')+
theme_classic()
# Time of Day x Pace
ggplot(data = alex_data,
aes(x = Time.of.Day, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'red') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Time of Day', x = 'Time of Day (Military Clock)', y = 'Running Pace in Miles Per Hour')+
theme_classic()
# Duration x Pace
p1 = ggplot(data = alex_data,
aes(x = Run.Minutes, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'red') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Run Duration', x = 'Run Duration in Minutes', y = 'Running Pace in Miles Per Hour')+
theme_classic()
# Laps x Pace
p2 = ggplot(data = alex_data,
aes(x = Laps, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'red') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Laps Run', x = 'Total Laps Run', y = 'Running Pace in Miles Per Hour')+
theme_classic()
# Total Days x Pace
p3 = ggplot(data = alex_data,
aes(x = Total.Days.Since.Start, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'green') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Total Days Since Start', x = 'Total Days Since Start', y = 'Running Pace in Miles Per Hour')+
theme_classic()
# Time of Day x Pace
p4 = ggplot(data = alex_data,
aes(x = Time.of.Day, y = Pace.mph)) +
geom_smooth(method = "lm", color = 'red') +
geom_point(shape = 21,
size = 3,
fill ="grey10",
alpha = .3) +
labs(title = 'Pace by Time of Day', x = 'Time of Day (Military Clock)', y = 'Running Pace in Miles Per Hour')+
theme_classic()
grid.arrange(p1, p2, p3, p3, nrow = 2)
library(gridExtra)
grid.arrange(p1, p2, p3, p3, nrow = 2)
grid.arrange(p1, p2, p3, p4, nrow = 2)
lm(Pace.mph ~ Run.Minutes + Laps + Total.Days.Since.Start + Time.of.Day, data = alex_data)
summary(lm(Pace.mph ~ Run.Minutes + Laps + Total.Days.Since.Start + Time.of.Day, data = alex_data))
corr_matrix
summary(lm(scale(Pace.mph) ~ scale(Run.Minutes) + scale(Laps) + scale(Total.Days.Since.Start) + scale(Time.of.Day), data = alex_data))
anova(aov(Weight_04 ~ CigWeek_04 + Diabetes_04, data = lab.data))
Anova(aov(Weight_04 ~ CigWeek_04 + Diabetes_04, data = lab.data), type = 2)
# To graph this result:
graph.data <-
lab.data %>%
filter(!is.na(Diabetes_04), !is.na(sex.code)) %>%
group_by(Diabetes_04) %>%
summarise(mean = mean(Weight_04, na.rm = T),
sd = sd(Weight_04, na.rm = T),
N = length(Weight_04)) %>%
mutate(se = sd / sqrt(N))
ggplot(data = graph.data,
aes(x = Diabetes_04, y = mean)) +
geom_bar(stat="identity",
color = "black",
position = position_dodge(),
fill = "lightblue") +
geom_errorbar(width = .5,
aes(ymin = mean - se, ymax = mean + se),
position = position_dodge(.9)) +
theme_classic() +
labs(y = "Av Weight",
x = "Diabetes Status")
ggplot(data = graph.data,
aes(x = Diabetes_04, y = mean)) +
geom_bar(stat="identity",
color = "black",
position = position_dodge(),
fill = "lightblue") +
geom_errorbar(width = .5,
aes(ymin = mean - se, ymax = mean + se),
position = position_dodge(.9)) +
theme_classic() +
labs(y = "Av Weight",
x = "Diabetes Status")
anova(aov(Depression_04 ~ Depression_01 + school.group, data = lab.data))
# First, I will create empty variables with only NA values, so I can recode them.
lab.data$c1 <- NA
lab.data$c2 <- NA
# To recode the first contrast (C1):
lab.data$c1[which(lab.data$school.group == "High School or Less")] <- 0
lab.data$c1[which(lab.data$school.group == "College (Undergraduate)")] <- 1
lab.data$c1[which(lab.data$school.group == "Graduate School")] <- -1
# To recode the second contrast (C2):
lab.data$c2[which(lab.data$school.group == "High School or Less")] <- 1
lab.data$c2[which(lab.data$school.group == "College (Undergraduate)")] <- -.5
lab.data$c2[which(lab.data$school.group == "Graduate School")] <- -.5
# To run the contrasts:
anova(aov(Depression_04 ~  Depression_01 + c1 + c2, data = lab.data))
summary(lm(scale(Depression_04) ~ scale(HowOftenChurch_04), data = lab.data))
Anova(aov(Satisfied_04 ~ Bible_04 + married_04, data = arh_data), type = 2)
Anova(aov(Bible_04 ~ Satisfied_04 * married_04, data = arh_data), type = 2)
nrow(arh_data)
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Divorced")))
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Married")))
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Never Married")))
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Separated")))
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Widowed")))
ggplot(data = arh_data,
aes(x = Satified_04, y = Bible_04, fill = married_04)) +
geom_smooth(method = "lm",
fullrange = T,
color = "black") +
geom_point(shape = 21,
alpha = .4) +
theme_classic() +
facet_wrap(~married_04)
ggplot(data = arh_data,
aes(x = Satisfied_04, y = Bible_04, fill = married_04)) +
geom_smooth(method = "lm",
fullrange = T,
color = "black") +
geom_point(shape = 21,
alpha = .4) +
theme_classic() +
facet_wrap(~married_04)
ggplot(data = arh_data,
aes(x = Satisfied_04, y = Bible_04, fill = married_04)) +
geom_smooth(method = "lm",
fullrange = T,
color = "black") +
ylim(-5, 10)+
geom_point(shape = 21,
alpha = .4) +
theme_classic() +
facet_wrap(~married_04)
arh_data = filter(arh_data, married_04 != 'NA')
Anova(aov(Bible_04 ~ Satisfied_04 * married_04, data = arh_data), type = 2)
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Divorced")))
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Married")))
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Never Married")))
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Separated")))
summary(lm(scale(Bible_04) ~ scale(Satisfied_04),
data = lab.data %>% filter(married_04 == "Widowed")))
ggplot(data = arh_data,
aes(x = Satisfied_04, y = Bible_04, fill = married_04)) +
geom_smooth(method = "lm",
fullrange = T,
color = "black") +
ylim(-5, 10)+
geom_point(shape = 21,
alpha = .4) +
theme_classic() +
facet_wrap(~married_04)
ggplot(data = arh_data,
aes(x = Satisfied_04, y = Bible_04, fill = married_04)) + lab(x = 'Life Satisfaction', y = 'Daily Bible Reading') +
geom_smooth(method = "lm",
fullrange = T,
color = "black") +
ylim(-5, 10)+
geom_point(shape = 21,
alpha = .4) +
theme_classic() +
facet_wrap(~married_04)
ggplot(data = arh_data,
aes(x = Satisfied_04, y = Bible_04, fill = married_04)) + labs(x = 'Life Satisfaction', y = 'Daily Bible Reading') +
geom_smooth(method = "lm",
fullrange = T,
color = "black") +
ylim(-5, 10)+
geom_point(shape = 21,
alpha = .4) +
theme_classic() +
facet_wrap(~married_04)
ggplot(data = arh_data,
aes(x = Satisfied_04, y = Bible_04, fill = married_04)) + labs(x = 'Life Satisfaction', y = 'Daily Bible Reading') +
geom_smooth(method = "lm",
fullrange = T,
color = "black") +
ylim(0, 10)+
geom_point(shape = 21,
alpha = .4) +
theme_classic() +
facet_wrap(~married_04)
aov(Depression_04 ~ married_04, data = arh_data)
summary(aov(Depression_04 ~ married_04, data = arh_data))
anova(aov(Depression_04 ~ Depression_01 + married_04, data = arh_data))
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('ggplot2')
# Reads in data file
data = read.csv('../Disjunction_Junction/Data&Resources/test_data.csv')
data = data %>%
mutate(ID = as.factor(id))
# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)
# Reads in key file
key = read.csv('../Disjunction_Junction/Data&Resources/disjunction_junction_key.csv')
# Factorizes IS column
key$ID = as_factor(key$ID)
# Joins key and data
data = left_join(data, key, by = 'ID')
means = data %>%
group_by(ID) %>%
summarise(Mean_Chance = mean(chance),
Standard_Deviation = sd(chance),
Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means)
View(means)
View(data)
# Reads in data file
data = read.csv('../Disjunction_Junction/Data&Resources/test_data.csv')
# Factorizes and renames id column
data = data %>%
mutate(ID = as.factor(id))
# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)
# Reads in key file
key = read.csv('../Disjunction_Junction/Data&Resources/disjunction_junction_key.csv')
# Factorizes IS column
key$ID = as_factor(key$ID)
# Joins key and data
data = left_join(data, key, by = 'ID')
table(data$Claimed.Bias)
# Reads in data file
data = read.csv('../Disjunction_Junction/Data&Resources/test_data.csv')
# Factorizes and renames id column
data = data %>%
mutate(ID = as.factor(id))
# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)
# Reads in key file
key = read.csv('../Disjunction_Junction/Data&Resources/disjunction_junction_key.csv')
# Factorizes IS column
key$ID = as_factor(key$ID)
# Joins key and data
data = left_join(data, key, by = 'ID')
table(data$Claimed.Bias)
model_data = data %>% filter(Claimed.Bias != 'N/A')
table(model_data$Claimed.Bias)
# transform column into factor
model_data$Claimed.Bias = as_factor(model_data$Claimed.Bias)
library('lme4)
library('lme4')
library('lme4')
glmer(chance ~ item + Claimed.Bias + (1 | workerid), data = model_data)
glmer(chance ~ ID + Claimed.Bias + (1 | workerid), data = model_data)
model_1 = glmer(chance ~ ID + Claimed.Bias + (1 | workerid), data = model_data)
model_1 = lmer(chance ~ ID + Claimed.Bias + (1 | workerid), data = model_data)
summary(model_1)
# An exploratory basic lm()
model_0 = lm(chance ~ Claimed.Bias, data = model_data)
summary(model_0)
View(data)
cntr_100 = data %>% filter(ID = c(66, 67, 68))
cntr_100 = data %>% filter(ID == c(66, 67, 68))
View(cntr_100)
View(model_data)
View(data)
table(data$ID)
cntr_100 = data %>% filter(ID == 66 | ID == 67 | ID == 68)
View(cntr_100)
#Filter just the 0% control items
cntr_0 = data %>% filter(ID == 69 | ID == 70 | ID == 71)
View(cntr_0)
cntr_100$correct = cntr_100$chance >= 85
View(cntr_100)
#combines the items
accuracy_check = rbind(cntr_0, cntr_100)
cntr_100$correct = cntr_100$chance >= 85
View(cntr_0)
#Filter just the 100% control items
cntr_100 = data %>% filter(ID == 66 | ID == 67 | ID == 68)
#Filter just the 0% control items
cntr_0 = data %>% filter(ID == 69 | ID == 70 | ID == 71)
#Adds a column for accuracy
cntr_100$correct = cntr_100$chance >= 85
cntr_0$correct = cntr_0$chance <= 15
View(cntr_0)
#combines the items
accuracy_check = rbind(cntr_0, cntr_100)
View(accuracy_check)
#Creates a table with the aggregated mean accuracy for each participant
accuracy_table = accuracy_check %>% group_by(workerid) %>% summarise(mean_accuracy = mean(correct))
View(accuracy_table)
#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = ID)
#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = workerid)
#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = 'workerid')
View(data)
#Filter out participants who got less than 5/6 correct
data = data %>% filter(mean_accuracy !< 80)
#Filter out participants who got less than 5/6 correct
data = data %>% filter(mean_accuracy > 80)
# Reads in data file
data = read.csv('../Disjunction_Junction/Data&Resources/test_data.csv')
# Factorizes and renames id column
data = data %>%
mutate(ID = as.factor(id))
# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)
# Reads in key file
key = read.csv('../Disjunction_Junction/Data&Resources/disjunction_junction_key.csv')
# Factorizes IS column
key$ID = as_factor(key$ID)
# Joins key and data
data = left_join(data, key, by = 'ID')
#Filter just the 100% control items
cntr_100 = data %>% filter(ID == 66 | ID == 67 | ID == 68)
#Filter just the 0% control items
cntr_0 = data %>% filter(ID == 69 | ID == 70 | ID == 71)
#Adds a column for accuracy
cntr_100$correct = cntr_100$chance >= 90
cntr_0$correct = cntr_0$chance <= 10
#Combines the items
accuracy_check = rbind(cntr_0, cntr_100)
#Creates a table with the aggregated mean accuracy for each participant
accuracy_table = accuracy_check %>% group_by(workerid) %>% summarise(mean_accuracy = mean(correct))
#Join the accuracy table to the rest of the data
data = left_join(data, accuracy_table, by = 'workerid')
#Filter out participants who got less than 5/6 correct
data = data %>% filter(mean_accuracy > .8)
View(data)
means = data %>%
group_by(ID) %>%
summarise(Mean_Chance = mean(chance),
Standard_Deviation = sd(chance),
Standard_Error = Standard_Deviation/sqrt(length(unique(data$workerid))))
print(means)
g = ggplot(data, aes(ID, chance))
g + geom_boxplot() + labs(title = 'Means and Variation by Item', x = 'Items (1-71)', y = 'Chance (%)')+
geom_dotplot(binaxis='y',
stackdir='center',
dotsize = .5,
binwidth = 3,
fill="red") +
theme_bw() +
theme(axis.text.x = element_blank())
# Filter out items with no recorded bias claim
model_data = data %>% filter(Claimed.Bias != 'N/A')
# transform column into factor
model_data$Claimed.Bias = as_factor(model_data$Claimed.Bias)
model_0 = lm(chance ~ Claimed.Bias, data = model_data)
summary(model_0)
# Reads in data file
data = read.csv('../Disjunction_Junction/Data&Resources/test_data.csv')
# Factorizes and renames id column
data = data %>%
mutate(ID = as.factor(id))
# Select just the columns needed for analysis
data = data %>% select(workerid, ID, chance)
# Reads in key file
key = read.csv('../Disjunction_Junction/Data&Resources/disjunction_junction_key.csv')
# Factorizes IS column
key$ID = as_factor(key$ID)
# Joins key and data
data = left_join(data, key, by = 'ID')
g + geom_boxplot() + labs(title = 'Means and Variation by Item', x = 'Items (1-71)', y = 'Chance (%)')+
geom_dotplot(binaxis='y',
stackdir='center',
dotsize = .5,
binwidth = 3,
fill="red") +
theme_bw() +
theme(axis.text.x = element_blank())
g = ggplot(data, aes(ID, chance))
g + geom_boxplot() + labs(title = 'Means and Variation by Item', x = 'Items (1-71)', y = 'Chance (%)')+
geom_dotplot(binaxis='y',
stackdir='center',
dotsize = .5,
binwidth = 3,
fill="red") +
theme_bw() +
theme(axis.text.x = element_blank())
